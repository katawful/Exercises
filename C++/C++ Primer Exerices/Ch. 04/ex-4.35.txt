Given the definitions, identify implicit type conversions if any

a) cval = 'a' + 3;
'a' gets converted to int.
The result of 'a' + 3 is then converted to a char type

b) fval = ui - ival * 1.0;
ival * 1.0 gets converted to a float
Then ui - ival gets converted to a unsigned int
Then the result gets converted to a float

c) dval = ui * fval;
ui * fval gets converted to a float
Then the result gets converted a double

d) cval = ival + fval + dval;
ival + fval gets converted to a float
Then that result + dval gets converted to a double
That result is then converted to a char
